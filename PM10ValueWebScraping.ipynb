{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e32d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function for scraping the PM10 values from a website\n",
    "def PM10_Value_Web_Scraper():\n",
    "    # Set up Chrome options to run in headless mode to avoid opening a browser window\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "\n",
    "    # Set up the ChromeDriver service to run the Chrome browser\n",
    "    service = Service(r'C:\\Users\\Konstantinos\\Desktop\\PM10ValueWebScraping\\chromedriver_win32')\n",
    "    \n",
    "    # Initialize the Chrome browser with the specified service and options\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Navigate to the specified webpage\n",
    "    url = 'https://www.infoaria.regione.lombardia.it/infoaria/#/stato-attivazione'\n",
    "    driver.get(url)\n",
    "\n",
    "    # Get the current date and format it as a string\n",
    "    today = datetime.date.today()\n",
    "    yesterday = today - datetime.timedelta(days=1)\n",
    "    date_string = yesterday.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create a list to store the PM10 values for each province\n",
    "    pm10_values = []\n",
    "\n",
    "    # Loop through the provinces and extract the PM10 value for each one\n",
    "    for province in range(1, 12):\n",
    "        # Construct the XPath string to locate the PM10 value for the current province on the webpage\n",
    "        xpath_string = \"//*[@id='content']/app-stato-attivazione/div[2]/div/div[2]/div[\" + str(province) + \"]/div/div[4]/div[1]/strong\"\n",
    "        try:\n",
    "            # Find the HTML element that contains the PM10 value for the current province\n",
    "            strong_element = driver.find_element(By.XPATH, xpath_string)\n",
    "            try:\n",
    "                # Extract the PM10 value from the HTML element as a string\n",
    "                extracted_pm10_value = strong_element.get_attribute('innerHTML')\n",
    "                # Define a regular expression pattern to match the PM10 value\n",
    "                pattern = r'\\d+\\.\\d+'\n",
    "                # Find all matches of the pattern in the extracted PM10 value\n",
    "                matches = re.findall(pattern, extracted_pm10_value)\n",
    "                if matches:\n",
    "                    # Convert the matched string to a decimal number\n",
    "                    final_pm10_value = float(matches[0])\n",
    "                    # Add the PM10 value for the current province to the list of PM10 values\n",
    "                    pm10_values.append(final_pm10_value)\n",
    "                else:\n",
    "                    # Add None to the list of PM10 values if no match is found\n",
    "                    pm10_values.append(None)\n",
    "            except:\n",
    "                # Add None to the list of PM10 values if an exception occurs\n",
    "                pm10_values.append(None)\n",
    "        except NoSuchElementException:\n",
    "            # Add None to the list of PM10 values if the HTML element for the current province cannot be found\n",
    "            pm10_values.append(None)\n",
    "\n",
    "    # Quit the browser driver to free up resources\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a header row for the CSV file\n",
    "    header = ['Date', 'Bergamo', 'Brescia', 'Como', 'Cremona', 'Lecco', 'Praise', 'Mantua', 'Milano', 'Monza Brianza', 'Pavia', 'Varese']\n",
    "\n",
    "    # Create a data row for the CSV file\n",
    "    data = [date_string] + pm10_values\n",
    "\n",
    "    # Open the CSV file where the scraped values will be stored\n",
    "    with open('PM10ValueWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:\n",
    "            # Write the header row to the CSV file, if it doesn't exist yet\n",
    "            writer.writerow(header)\n",
    "        # Write the data row to the CSV file\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584ca739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KONSTA~1\\AppData\\Local\\Temp/ipykernel_14352/2649519288.py:17: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True\n",
      "Incompatible release of chromedriver (version 112.0.5615.49) detected in PATH: C:\\Users\\Konstantinos\\Desktop\\PM10ValueWebScraping\\chromedriver.exe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Bergamo</th>\n",
       "      <th>Brescia</th>\n",
       "      <th>Como</th>\n",
       "      <th>Cremona</th>\n",
       "      <th>Lecco</th>\n",
       "      <th>Praise</th>\n",
       "      <th>Mantua</th>\n",
       "      <th>Milano</th>\n",
       "      <th>Monza Brianza</th>\n",
       "      <th>Pavia</th>\n",
       "      <th>Varese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Bergamo  Brescia  Como  Cremona  Lecco  Praise  Mantua  Milano  \\\n",
       "0  2023-05-11      NaN      NaN  12.7      9.8   13.0     8.7     NaN     NaN   \n",
       "1  2023-05-12      NaN      NaN   NaN      NaN    NaN     NaN     NaN     NaN   \n",
       "2  2023-05-13      NaN      NaN   NaN      NaN    NaN     NaN     NaN     NaN   \n",
       "3  2023-05-14      NaN      NaN   NaN      7.0    NaN     7.4     NaN     NaN   \n",
       "\n",
       "   Monza Brianza  Pavia  Varese  \n",
       "0            NaN   10.7     9.8  \n",
       "1            NaN    NaN     NaN  \n",
       "2            NaN    NaN     NaN  \n",
       "3            NaN    NaN     5.3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the PM10_Value_Web_Scraper function to scrape the website and store the data in a CSV file\n",
    "PM10_Value_Web_Scraper()\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\Konstantinos\\Desktop\\PM10ValueWebScraping\\PM10ValueWebScraperDataset.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
